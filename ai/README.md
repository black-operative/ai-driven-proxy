# AI Classification Service

This directory contains the machine learning pipeline and classifier service that powers the AI-driven proxy. It handles model training, data preprocessing, traffic classification, and provides a socket-based service for real-time predictions.

## Overview

The AI service:

- **Trains** classification models on network traffic features
- **Classifies** network requests as BENIGN, BOT, or ATTACK
- **Communicates** with the proxy via TCP socket for real-time predictions
- **Analyzes** proxy decision logs and performance metrics

## Directory Structure

```bash
ai/
├── README.md                    # This file
├── scripts/
│   ├── classifier.py            # Main AI service (runs in parallel with proxy)
│   ├── cicids_to_dataset.py     # Convert CICIDS raw data → normalized dataset
│   └── analysis.py              # Visualization and analysis of proxy logs
├── data/
│   ├── dataset.csv              # Primary training/test dataset (normalized)
│   ├── Friday-DDOS.csv          # CICIDS raw data (DDoS attacks)
│   ├── Tuesday-Normal.csv       # CICIDS raw data (normal traffic)
│   └── copy.csv                 # Working copy (generated by analysis.py)
└── model/
    └── model.pkl                # Trained classifier (scikit-learn format)
```

## Quick Start

### 1. Prepare the Environment

```bash
python3 -m venv .venv
source .venv/bin/activate
pip install pandas numpy scikit-learn matplotlib
```

### 2. Generate Dataset

If you have CICIDS raw CSV files in `data/`:

```bash
cd scripts/
python3 cicids_to_dataset.py
```

This converts multi-source CICIDS CSV files into a unified `dataset.csv` with normalized feature names:

- `payload_size` - Total length of forward packets (bytes)
- `header_size` - Forward packet header length (bytes)
- `request_count` - Total forward packets count
- `inter_arrival_us` - Inter-arrival time (microseconds)
- `label` - Traffic class (BENIGN, BOT, ATTACK)

### 3. Train the Model

*(See parent repository for training scripts—this assumes `model.pkl` exists)*

The model must be a scikit-learn estimator with `.predict()` and `.predict_proba()` methods.

### 4. Run the Classifier Service

```bash
cd scripts/
python3 classifier.py
```

The service:

- Listens on `127.0.0.1:5000` (TCP socket)
- Accepts serialized `Feature_Vector` (24 bytes): 4 uint32 + 1 uint64 (IIIQ format)
- Returns prediction + confidence (1 byte + 4-byte float)
- Blocks until the proxy connects

### 5. Analyze Results

After running the proxy:

```bash
python3 analysis.py
```

Generates four matplotlib windows:

- **Confidence Over Time** - Decision quality over test period
- **Latency Distribution** - AI inference time by decision type
- **Confidence vs. Latency** - Correlation scatter plot
- **Decision Counts** - Total ALLOW vs. BLOCK distribution

## File Reference

### `classifier.py`

**Purpose:** Real-time AI classification service for the proxy

**Key details:**

- Loads trained model from `model.pkl`
- Opens TCP socket on port 5000
- Waits for proxy connection
- Deserializes incoming feature vectors (24 bytes)
- Runs prediction + confidence scoring
- Sends back traffic type + confidence

**Usage:**

```bash
python3 classifier.py
```

**Expected format (binary):**

```plaintext
Incoming (24 bytes) : uint32, uint32, uint32, uint64
                      (payload_size, header_size, request_count, inter_arrival_us)

Outgoing (5 bytes)  : uint8, float32
                      (traffic_type, confidence)
```

### `cicids_to_dataset.py`

**Purpose:** Convert raw CICIDS CSV files into normalized proxy dataset

**Workflow:**

1. Glob all CSV files in current directory
2. Concatenate into single dataframe
3. Select and rename columns to match `Feature_Vector`
4. Clean: drop NaN, filter invalid values
5. Convert milliseconds → microseconds
6. Map labels: BENIGN, BOT, ATTACK
7. Output `dataset.csv`

**Run before training if you have raw CICIDS data.**

### `analysis.py`

**Purpose:** Visualize proxy performance and AI accuracy

**Functions:**

- Loads proxy metrics from `copy.csv` (generated from proxy logs)
- Augments with synthetic test data
- Creates four matplotlib figures:
  - Confidence trajectory
  - Latency box plots
  - Confidence-latency correlation
  - Decision distribution

**Note:** Requires `copy.csv` (proxy output) or generates synthetic data.

## Data Formats

### Input: Feature Vector (from proxy)

The proxy extracts 4 features per request:

| Field | Type | Source | Notes |
|-------|------|--------|-------|
| `payload_size` | uint32 | HTTP body | bytes |
| `header_size` | uint32 | HTTP headers | bytes |
| `request_count` | uint32 | Per-connection | cumulative |
| `inter_arrival_us` | uint64 | Timing | microseconds |

### Output: AI Result (to proxy)

| Field | Type | Range | Meaning |
|-------|------|-------|---------|
| `type` | uint8 | 0-2 | 0=BENIGN, 1=BOT, 2=ATTACK |
| `confidence` | float32 | 0.0-1.0 | Model confidence |

### Dataset CSV Schema

```csv
payload_size,header_size,request_count,inter_arrival_us,label
12.0,40.0,2.0,3000,BENIGN
```

- 671,645 rows (typical full dataset)
- Labels: BENIGN, BOT, ATTACK
- Features normalized to proxy metrics

## Integration with Proxy

The classifier runs as a separate process communicating via TCP socket:

```plaintext
Proxy (C++)                             Classifier (Python)
    ↓                                         ↓
Create Feature_Vector ── [serialize] ──→ classifier.py:5000
                                          ├─ Load model.pkl
                                          ├─ Predict
                                          └─ Return confidence
    ↓                                         ↓
Receive AI_Result ←── [deserialize] ─── socket response
    ↓
Policy_Engine (allow/deny decision)
```

## Performance Notes

- **Socket communication:** ~50-70 microseconds (typical latency)
- **Model inference:** Depends on classifier (scikit-learn ~0.5-2ms)
- **Serialization:** 24 bytes in, 5 bytes out (minimal overhead)

See `analysis.py` output for actual latency distributions.

## Requirements

- Python 3.7+
- pandas
- numpy
- scikit-learn (for model format)
- matplotlib (for analysis.py)

Install all:

```bash
pip install pandas numpy scikit-learn matplotlib
```

## Notes

- **Model training:** Not included in this directory. Assumes `model.pkl` pre-exists or is trained externally.
- **CICIDS data:** Raw files (`Friday-DDOS.csv`, `Tuesday-Normal.csv`) are reference datasets; run `cicids_to_dataset.py` to normalize.
- **Proxy logs:** `analysis.py` expects `copy.csv` from proxy `proxy_metrics.csv` output.
- **Socket protocol:** Tightly coupled to C++ `Feature_Vector` struct size (24 bytes); changes require proxy rebuild.

## Troubleshooting

| Issue | Solution |
|-------|----------|
| Connection refused | Check proxy is running; ensure port 5000 is free |
| Serialization error | Verify data types match struct format (IIIQ) |
| No `model.pkl` found | Train or provide pre-trained model file |
| Import errors | Install dependencies: `pip install -r requirements.txt` |

## References

- Parent: [../proxy/README.md](../proxy/README.md) for proxy server documentation
- CICIDS dataset: <https://www.unb.ca/cic/datasets/ids-2017.html>
- Scikit-learn serialization: <https://scikit-learn.org/stable/modules/model_persistence.html>
